# Architecture Decision Records (ADRs)

Este documento registra decis√µes arquiteturais importantes tomadas durante o desenvolvimento do `@luoarch/baileys-store-core`.

## ADR-001: Hybrid Storage Pattern (Redis + MongoDB)

**Status:** ‚úÖ Accepted  
**Data:** Outubro 2025  
**Contexto:** Baileys sessions precisam de baixa lat√™ncia para opera√ß√µes frequentes (< 10ms) e persist√™ncia dur√°vel para recovery de desastres. O WhatsApp Multi-Device requer acesso ultra-r√°pido a keys de criptografia para opera√ß√µes de S/M.

**Decis√£o:**  
Implementar hybrid storage combinando Redis (hot cache in-memory) com MongoDB (cold storage persistente).

- **Redis**: Armazena dados cr√≠ticos em mem√≥ria para acesso sub-milissegundo
- **MongoDB**: Persiste todos os dados com garantias ACID e TTL autom√°tico
- **Estrat√©gia**: Write-through para opera√ß√µes cr√≠ticas (creds, keys) e write-behind para appState

**Consequ√™ncias Positivas:**
- ‚úÖ Lat√™ncia p99 < 20ms em cache hits (vs ~100ms MongoDB direto)
- ‚úÖ Durabilidade garantida (MongoDB replica set)
- ‚úÖ Escalabilidade horizontal (Redis Cluster + MongoDB Sharding)
- ‚úÖ Circuit breaker permite degrada√ß√£o graceful (Redis-only mode)

**Trade-offs:**
- ‚ö†Ô∏è Complexidade adicional: 2 sistemas para gerenciar
- ‚ö†Ô∏è Consist√™ncia eventual em modo async (RPO < 1s aceit√°vel)
- ‚ö†Ô∏è Custos operacionais maiores (Redis + MongoDB)

**Alternativas Consideradas:**

| Alternativa | Por que n√£o foi escolhida |
|------------|---------------------------|
| **Redis-only** | Sem persist√™ncia dur√°vel, risco de perda total de dados |
| **MongoDB-only** | Lat√™ncia muito alta (p99 ~100ms) inaceit√°vel para opera√ß√µes cr√≠ticas |
| **PostgreSQL** | Overhead para opera√ß√µes key-value, performance inferior ao MongoDB |
| **Cassandra** | Complexidade excessiva para este caso de uso |

**M√©tricas de Sucesso:**
- Cache hit rate > 80%
- p99 latency < 20ms (cache hit)
- Durabilidade 99.99% (MongoDB)

---

## ADR-002: Transactional Outbox Pattern

**Status:** ‚úÖ Accepted  
**Data:** Outubro 2025  
**Contexto:** No modo write-behind (async), precisamos garantir que dados escritos no Redis sejam eventualmente persistidos no MongoDB mesmo ap√≥s falhas.

**Decis√£o:**  
Implementar Transactional Outbox Pattern com reconciliation worker.

**Arquitetura:**
1. Opera√ß√£o write adiciona evento ao Redis SET (outbox)
2. Redis write √© confirmado imediatamente (low latency)
3. Background worker processa outbox e persiste no MongoDB
4. Evento removido da outbox ap√≥s persist√™ncia confirmada
5. Reconciliation job verifica outbox a cada 60s para eventos √≥rf√£os

**Consequ√™ncias Positivas:**
- ‚úÖ Garantia de eventual consistency (no-publish, no-duplicate)
- ‚úÖ Recovery autom√°tico de falhas (reconciliation)
- ‚úÖ Baixa lat√™ncia mantida (Redis immediate)
- ‚úÖ Compat√≠vel com m√∫ltiplos workers (idempot√™ncia)

**Trade-offs:**
- ‚ö†Ô∏è Complexidade adicional: Worker, reconciliation, dedup
- ‚ö†Ô∏è Janela de inconsist√™ncia (p99 < 1s) em caso de falha
- ‚ö†Ô∏è Espa√ßo adicional: Outbox storage (~1KB por evento)

**Alternativas Consideradas:**

| Alternativa | Por que n√£o foi escolhida |
|------------|---------------------------|
| **Two-Phase Commit (2PC)** | Bloqueante, lat√™ncia alta, n√£o adequado para alta carga |
| **Saga Pattern** | Complexidade excessiva para este caso de uso |
| **Event Sourcing** | Over-engineering, n√£o necess√°rio para este dom√≠nio |
| **Publish-Subscribe** | Depend√™ncia externa (Kafka, etc) adiciona custos |

**M√©tricas de Sucesso:**
- Outbox processamento p99 < 1s
- Outbox lag < 5s (p95)
- Zero data loss em testes de stress

---

## ADR-003: AES-256-GCM vs XSalsa20-Poly1305 (secretbox)

**Status:** ‚úÖ Accepted  
**Data:** Outubro 2025  
**Contexto:** Necessidade de criptografar dados sens√≠veis (keys, creds) antes de persistir. Duas op√ß√µes principais: AES-256-GCM (padr√£o NIST) e XSalsa20-Poly1305 (TweetNaCl).

**Decis√£o:**  
Suportar ambos os algoritmos, defaultando para **secretbox** (XSalsa20-Poly1305).

**Justificativa:**
- **Baileys v7 usa TweetNaCl nativamente** (compatibilidade total)
- **Zero dependencies extras** (TweetNaCl j√° inclu√≠do)
- **Velocidade superior** (~2x mais r√°pido que AES-GCM em benchmarks Node.js)
- **Navegadores**: TweetNaCl funciona em browser (paths futuros)

**Consequ√™ncias Positivas:**
- ‚úÖ Compatibilidade 100% com Baileys keys
- ‚úÖ Performance superior (menor CPU overhead)
- ‚úÖ Flexibilidade: AES-256-GCM dispon√≠vel para compliance requirements

**Trade-offs:**
- ‚ö†Ô∏è AES-256-GCM n√£o √© default (seguran√ßa "ferrovi√°ria")
- ‚ö†Ô∏è Complexidade adicional: Suporte a 2 algoritmos
- ‚ö†Ô∏è Testes mais complexos (2 codecs)

**Alternativas Consideradas:**

| Alternativa | Por que n√£o foi escolhida |
|------------|---------------------------|
| **AES-256-GCM only** | Incompat√≠vel com Baileys internal keys, overhead desnecess√°rio |
| **ChaCha20-Poly1305** | Similar ao XSalsa20, mas TweetNaCl j√° otimizado |
| **Sem criptografia** | Inseguro para dados em produ√ß√£o (keys, creds) |

**Configura√ß√£o:**
```typescript
security: {
  enableEncryption: true,
  encryptionAlgorithm: 'secretbox' | 'aes-256-gcm',
  masterKey: '<64-hex-chars>',
  keyRotationDays: 90,
}
```

**M√©tricas de Sucesso:**
- Encryption overhead < 5ms (p99)
- Key rotation transparente (< 10ms)
- Zero regress√µes de compatibilidade com Baileys

---

## ADR-004: Circuit Breaker Configuration

**Status:** ‚úÖ Accepted  
**Data:** Outubro 2025  
**Contexto:** MongoDB pode ficar indispon√≠vel por m√∫ltiplas raz√µes (manuten√ß√£o agendada, rede inst√°vel, OOM, etc). Precisamos degradar gracefully sem impactar opera√ß√µes cr√≠ticas.

**Decis√£o:**  
Implementar Circuit Breaker usando Opossum com configura√ß√£o agressiva.

**Configura√ß√£o:**
- **Error threshold**: 50% (ap√≥s 5 de 10 requests falharem)
- **Timeout**: 30 segundos (volta para half-open)
- **Reset timeout**: 30 segundos antes de tentar novamente
- **Monitoring**: M√©tricas Prometheus (open/closed/half-open transitions)

**Estados:**
1. **Closed**: Normal operation, requests passam para MongoDB
2. **Open**: MongoDB considerado down, todas requests bloqueadas (Redis-only mode)
3. **Half-Open**: Probing phase (1 request testado)

**Consequ√™ncias Positivas:**
- ‚úÖ Degradation gracefully (Redis-only mode mant√©m opera√ß√£o)
- ‚úÖ Recupera√ß√£o autom√°tica ap√≥s MongoDB voltar
- ‚úÖ Prote√ß√£o contra cascading failures
- ‚úÖ Observabilidade completa (Prometheus metrics)

**Trade-offs:**
- ‚ö†Ô∏è Janela de poss√≠vel inconsist√™ncia (MongoDB down)
- ‚ö†Ô∏è Pode abrir prematuramente com falso positivo (50% threshold)
- ‚ö†Ô∏è Write operations bloqueadas quando open (trade-off por seguran√ßa)

**Alternativas Consideradas:**

| Alternativa | Por que n√£o foi escolhida |
|------------|---------------------------|
| **Retry infinito** | Cascading failure, latency spikes |
| **Fail-fast sem retry** | Pior UX, perda de durabilidade |
| **Exponential backoff** | N√£o resolve problema de MongoDB down |
| **Health checks peri√≥dicos** | Overhead adicional, lat√™ncia de detec√ß√£o |

**M√©tricas de Sucesso:**
- Circuit breaker false positives < 5%
- Recovery time < 30s ap√≥s MongoDB back online
- Availability 99.95% mesmo com MongoDB intermittent failures

**C√≥digo de Exemplo:**
```typescript
this.mongoCircuitBreaker = new CircuitBreaker(mongoOperation, {
  errorThresholdPercentage: 50,
  timeout: 30000,
  resetTimeout: 30000,
  enabled: true,
});
```

---

## ADR-005: Capacity Planning Strategy

**Status:** ‚úÖ Accepted  
**Data:** Outubro 2025  
**Contexto:** Escalar de 1 sess√£o (desenvolvimento) para 10k+ sess√µes (produ√ß√£o) requer planejamento de infraestrutura.

**Decis√£o:**  
Estabelecer path incremental de scaling com checkpoints claros.

**Fases de Scaling:**

### Fase 1: Single Instance (0-100 sessions)
- **Config**: Single Redis + Single MongoDB
- **Node.js**: 1 pod (512Mi memory, 500m CPU)
- **Redis**: 1 instance (128MB memory)
- **MongoDB**: 1 replica (1GB memory)
- **Custo estimado**: $20-40/m√™s (cloud managed)

### Fase 2: High Availability (100-1000 sessions)
- **Config**: Redis Sentinel (3 nodes) + MongoDB Replica Set (3 nodes)
- **Node.js**: 2-3 pods (HPA baseado em CPU 70%)
- **Redis**: 3 instances (256MB cada)
- **MongoDB**: 3 replicas (2GB cada, primary + 2 secondaries)
- **Custo estimado**: $150-250/m√™s

### Fase 3: Horizontal Scaling (1000-5000 sessions)
- **Config**: Redis Cluster (6+ nodes) + MongoDB Sharded Cluster
- **Node.js**: 5-10 pods (auto-scaling, max 20 pods)
- **Redis**: 6+ nodes (512MB-1GB cada, sharded)
- **MongoDB**: 2-3 shards, replica set por shard (4GB each)
- **Custo estimado**: $500-800/m√™s

### Fase 4: Enterprise Scale (5000+ sessions)
- **Config**: Redis Cluster (12+ nodes) + MongoDB Multi-shard + Geo-distributed
- **Node.js**: 10-20 pods
- **Redis**: 12+ nodes (multi-region)
- **MongoDB**: 3+ shards, replicated across regions
- **Custo estimado**: $1500-3000/m√™s

**Consequ√™ncias Positivas:**
- ‚úÖ Path claro e incremental (upgrade gradual)
- ‚úÖ Custos scale com revenue (pode come√ßar barato)
- ‚úÖ Sem necessidade de re-architect antes de 10k sessions
- ‚úÖ Checkpoints definidos facilitam decision-making

**Trade-offs:**
- ‚ö†Ô∏è Necess√°rio reconfigurar em checkpoints (downtime planejado)
- ‚ö†Ô∏è Complexidade aumenta progressivamente (mais moving parts)
- ‚ö†Ô∏è Custos n√£o lineares (fase 3 √© ~5x da fase 1)

**Alternativas Consideradas:**

| Alternativa | Por que n√£o foi escolhida |
|------------|---------------------------|
| **Sharding desde fase 1** | Over-engineering, custo desnecess√°rio |
| **Vertical scaling only** | Limites f√≠sicos, n√£o escal√°vel al√©m de 8 cores/64GB |
| **Kubernetes native (StatefulSets)** | Complexidade excessiva para in√≠cio |

**Monitoring & Alerting:**
- **Mem√≥ria Redis**: Alerta se > 80% utilizada
- **Disk MongoDB**: Alerta se > 75% utilizado
- **Lat√™ncia p99**: Alerta se > 100ms
- **Cache hit rate**: Alerta se < 75%

**Automatic Scaling Triggers:**
- **Pods**: CPU > 70% por 5min ‚Üí scale up
- **Pods**: CPU < 30% por 15min ‚Üí scale down
- **Redis**: Memory > 80% ‚Üí Adicionar node (manual)
- **MongoDB**: Disk > 80% ‚Üí Increase storage (manual)

---

## Como Adicionar Novos ADRs

Ao adicionar um novo ADR:

1. Copiar template abaixo
2. Preencher com decis√£o e contexto
3. Adicionar √† lista acima (ordenado por data)
4. Atualizar este documento

**Template:**
```markdown
## ADR-XXX: [T√≠tulo Curto]

**Status:** üöß Proposed | ‚úÖ Accepted | ‚ùå Rejected  
**Data:** [Data]  
**Contexto:** [Por que est√° tomando esta decis√£o?]

**Decis√£o:**  
[O que decidiu?]

**Consequ√™ncias Positivas:**
- ‚úÖ [Benef√≠cio 1]
- ‚úÖ [Benef√≠cio 2]

**Trade-offs:**
- ‚ö†Ô∏è [Desvantagem/custo]

**Alternativas Consideradas:**
| Alternativa | Por que n√£o foi escolhida |
|------------|---------------------------|
| [Alt 1] | [Motivo] |
| [Alt 2] | [Motivo] |
```

---

**Refer√™ncias:**
- [ADR Template by Thoughtworks](https://www.thoughtworks.com/radar/techniques/lightweight-architecture-decision-records)
- [Documenting Architecture Decisions - Michael Nygard](https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions)
